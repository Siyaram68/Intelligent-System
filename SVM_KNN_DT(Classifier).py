**KNN Classification**
import pandas as pd
df=pd.read_csv("WineQT.csv")

df.head()
df=df.dropna()
df
df.isnull().sum()
X=df[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','Id']]
Y=df['quality']

X.head()
#Feature scaling or normalization

from sklearn.preprocessing import StandardScaler
ss=StandardScaler()

X=ss.fit_transform(X)
X
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)

from sklearn.neighbors import KNeighborsClassifier
model_knn=KNeighborsClassifier(n_neighbors=3)
model_knn.fit(X_train,Y_train)
#predicting
y_pred = model_knn.predict(X_test)

#finding accuracy

from sklearn.metrics import r2_score, classification_report, confusion_matrix,accuracy_score


print("Confusion Matrix:")
print(confusion_matrix(Y_test, y_pred))
print("\nClassification Report:")
print(classification_report(Y_test, y_pred))
print("\nAccuracy:", accuracy_score(Y_test, y_pred))

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], color='blue', label='X_train', alpha=0.6)
plt.scatter(X_test[:, 0], X_test[:, 1], color='red', label='X_test', alpha=0.6)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('X_train and X_test Visualization')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier(random_state=42)
DT.fit(X_train, Y_train)

y_pred = DT.predict(X_test)
from sklearn.neighbors import KNeighborsClassifier
model_knn=KNeighborsClassifier(n_neighbors=5)
model_knn.fit(X_train,Y_train)
#predicting
y_pred = model_knn.predict(X_test)

#finding accuracy

from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score


print("Confusion Matrix:")
print(confusion_matrix(Y_test, y_pred))
print("\nClassification Report:")
print(classification_report(Y_test, y_pred))
print("\nAccuracy:", accuracy_score(Y_test, y_pred))
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], color='blue', label='X_train', alpha=0.6)
plt.scatter(X_test[:, 0], X_test[:, 1], color='red', label='X_test', alpha=0.6)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('X_train and X_test Visualization')
plt.legend()
plt.grid(True)
plt.show()

# Support Vector Machine
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split


import pandas as pd
df=pd.read_csv("WineQT.csv")

df.head()
X=df[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','Id']]
Y=df['quality']

X.head()
#Feature scaling or normalization

from sklearn.preprocessing import StandardScaler
ss=StandardScaler()

X=ss.fit_transform(X)
X
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)
from sklearn.svm import SVC
model_linear=SVC(kernel='linear',random_state=1)
model_linear.fit(X_train,Y_train)
y_pred=model_linear.predict(X_test)
y_pred


from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score


print("Confusion Matrix:")
print(confusion_matrix(Y_test, y_pred))
print("\nClassification Report:")
print(classification_report(Y_test, y_pred))
print("\nAccuracy:", accuracy_score(Y_test, y_pred))
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], color='blue', label='X_train', alpha=0.6)
plt.scatter(X_test[:, 0], X_test[:, 1], color='red', label='X_test', alpha=0.6)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('X_train and X_test Visualization')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.svm import SVC
model_linear=SVC(kernel='rbf',random_state=1)
model_linear.fit(X_train,Y_train)
y_pred=model_linear.predict(X_test)
y_pred


from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score


print("Confusion Matrix:")
print(confusion_matrix(Y_test, y_pred))
print("\nClassification Report:")
print(classification_report(Y_test, y_pred))
print("\nAccuracy:", accuracy_score(Y_test, y_pred))
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], color='blue', label='X_train', alpha=0.6)
plt.scatter(X_test[:, 0], X_test[:, 1], color='red', label='X_test', alpha=0.6)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('X_train and X_test Visualization')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score

y_pred_knn = model_knn.predict(X_test)
y_pred_linear = model_linear.predict(X_test)

accuracy_knn = accuracy_score(Y_test, y_pred_knn)
accuracy_linear = accuracy_score(Y_test, y_pred_linear)

models = ['KNN Model', 'Linear Model']
accuracies = [accuracy_knn, accuracy_linear]

plt.figure(figsize=(10, 6))
sns.barplot(x=models, y=accuracies, palette='viridis')

plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Comparison of Model Accuracies')
plt.ylim(0, 1) 

plt.show()
